{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ededd5fa-4ea5-4055-beb5-2ead0f1cbdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8e1d6b6-ecaa-40aa-af5e-9952e137fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev import *\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4363959e-b31e-4325-9f9f-8d60ccbc4ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from HierarchicalGeoClustering.Tree_clusters import cluster_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb764f-3cf9-4bd3-8495-c4caed8c30aa",
   "metadata": {},
   "source": [
    "# Clustering \n",
    "\n",
    "In this file all the clustering methods are implemented \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215b9b2a-9ced-4043-87bd-950235e99ed6",
   "metadata": {},
   "source": [
    "## Compute DBSCAN\n",
    "A wapper function to obtain the DBSCAN cluters by levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3646c9cf-05c5-4d02-a3db-030b3834ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compute_dbscan(cluster,  **kwargs):\n",
    "    \n",
    "    \"\"\" \n",
    "    Sklearn DBSCAN wrapper.\n",
    "    \n",
    "    :param cluster: a (N,2) numpy array containing the obsevations\n",
    "\n",
    "    :returns list with numpy arrays for all the clusters obtained\n",
    "    \"\"\"\n",
    "    eps = kwargs.get( 'eps_DBSCAN',.04)\n",
    "    debugg= kwargs.get( 'debugg',False)\n",
    "    min_samples= kwargs.get( 'min_samples',50)\n",
    "    ret_noise = kwargs.get('return_noise', False)\n",
    "    # Standarize sample\n",
    "    scaler = StandardScaler()\n",
    "    cluster = scaler.fit_transform(cluster)\n",
    "    if debugg:\n",
    "        print('epsilon distance to DBSCAN: ', eps)\n",
    "        print(\"min_samples to DBScan: \", min_samples )\n",
    "        print(\"Number of points to fit the DBScan: \",cluster.shape[0])\n",
    "\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(cluster)  # Check if can be run with n_jobs = -1\n",
    "    \n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    labels = db.labels_\n",
    "    l_unique_labels = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    unique_labels = set(labels) \n",
    "    cluster = scaler.inverse_transform(cluster)\n",
    "    clusters = []\n",
    "    if debugg:\n",
    "        print('Number of clusters:' ,l_unique_labels)\n",
    "    \n",
    "    for l in unique_labels:\n",
    "        if l != -1:\n",
    "            class_member_mask = (labels == l)\n",
    "            clusters.append(cluster[class_member_mask])\n",
    "        elif l == -1 and debugg == True:\n",
    "            class_member_mask = (labels == l)\n",
    "            print(\"Muestras consideradas ruido: \",  sum(class_member_mask))\n",
    "    \n",
    "    if ret_noise == True:\n",
    "        class_member_mask = (labels == -1)\n",
    "        return clusters, cluster[class_member_mask]\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa88e40b-6f7a-480a-a346-25146d817c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "### Pruebas \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496cec4e-124d-4a83-a7ad-8a50f7dc5646",
   "metadata": {},
   "source": [
    "## Recursive Clustering \n",
    "The function obtains the clustering iterative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fadc0e6-da7b-4d25-9099-d45d05659d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def recursive_clustering(\n",
    "                this_level,  # Dictionary with Points\n",
    "                to_process,  # levels to process\n",
    "                cluster_tree,  # to store the clusters\n",
    "                level = 0,  # current level\n",
    "                algorithm ='dbscan',  # Algorithm to use\n",
    "                **kwargs\n",
    "               ):\n",
    "    \"\"\"\n",
    "    Performs the recursive clustering.\n",
    "    Calls compute_dbscan for each\n",
    "    list of clusters keepen the structure and then calls itself\n",
    "    until no more clusters satisfy the condition\n",
    "        \n",
    "    :param dict this_level: level is the current level \n",
    "    \n",
    "    :param int to_process: the max level to process\n",
    "    \n",
    "    :param double eps: The epsilon parameter distance to pass to the needed algorithm \n",
    "    \n",
    "    :param list cluster_tree : list of list to insert the levels \n",
    "    \n",
    "    :param bool verbose : To print \n",
    "    \n",
    "    :param double decay: In the use of dbscan the deacy parameter to reduce eps\n",
    "    \n",
    "    :param int min_points_cluster: The min point for each cluster to pass to algorithm\n",
    "    \n",
    "    :param str algorithm:  The string of the algorithm name to use\n",
    "    \"\"\"\n",
    "\n",
    "    verbose= kwargs.get('verbose',False)\n",
    "    min_points = kwargs.get( 'min_points_cluster', 50)\n",
    "    decay = kwargs.get('decay', 0.7)\n",
    "    eps = kwargs.get('eps' ,0.8)  # Epsilon distance to DBSCAN parameter\n",
    "    tmp = None\n",
    "\n",
    "    if level == 0:\n",
    "        kwargs['eps'] = eps\n",
    "    else:\n",
    "        kwargs['eps'] = eps  * decay\n",
    "\n",
    "    cluster_result_polygons = []\n",
    "    if level > to_process:\n",
    "        if verbose:\n",
    "            print('Done clustering')\n",
    "        return\n",
    "    ######## Get the clusters for the current list of points \n",
    "    all_l = clustering(\n",
    "                    this_level,\n",
    "                    level=level,\n",
    "                    algorithm=algorithm,\n",
    "                    \n",
    "                    **kwargs\n",
    "                    )\n",
    "    ##########\n",
    "\n",
    "    cluster_tree.append(all_l)\n",
    "    cluster_n = 0\n",
    "    for i in all_l:\n",
    "        cluster_n += len(i['points'])\n",
    "    if verbose:\n",
    "        print('At level ', level, ' the number of lists are ',\n",
    "              len(all_l), ' with ', cluster_n, 'clusters')\n",
    "    level += 1\n",
    "    if len(all_l) > 0:\n",
    "        return recursive_clustering(all_l, \n",
    "                               to_process=to_process,\n",
    "                               cluster_tree=cluster_tree,\n",
    "                               level= level,\n",
    "                               algorithm=algorithm,\n",
    "                               **kwargs\n",
    "                               )\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('done clustering')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372eacfa-9a9f-4485-bcfb-95710f57cf84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
